{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af7c8e06",
   "metadata": {},
   "source": [
    "# Set Path & Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b5c9718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = '/home/lab16/jupyter_home/models/RegNet_0.001_Lamb_CosineAnnealing_example.pth' # 0.9032258064516129\n",
    "# model_path = '/home/lab16/jupyter_home/models/RegNet_0.001_adam_CosineAnnealing_example.pth' # 0.6129032258064516\n",
    "# model_path = '/home/lab16/jupyter_home/models/RegNet_1e-05_adam_CosineAnnealing_example.pth' # 0.8387096774193549\n",
    "# model_path = '/home/lab16/jupyter_home/models/RegNet_1e-05_Lamb_CosineAnnealing_example.pth' # 0.3870967741935484\n",
    "model_path = '/home/lab16/jupyter_home/models/RegNet_1e-05_rmsprop_CosineAnnealing_example.pth' # 0.9354838709677419\n",
    "# model_path = '/home/lab16/jupyter_home/models/RegNet_1e-05_nadam_CosineAnnealing_example.pth' # 0.8709677419354839\n",
    "# model_path = '/home/lab16/jupyter_home/models/ResNet50_0.001_adam_CosineAnnealing_example.pth'  # 0.3548387096774194\n",
    "# model_path = '/home/lab16/jupyter_home/models/ResNet50_0.001_Lamb_CosineAnnealing_example.pth' # 0.7096774193548387\n",
    "# model_path = '/home/lab16/jupyter_home/models/ResNet50_0.001_rmsprop_CosineAnnealing_example.pth' # 0.1935483870967742\n",
    "# model_path = '/home/lab16/jupyter_home/models/ResNet50_1e-05_Lamb_CosineAnnealing_example.pth' # 0.12903225806451613\n",
    "# model_path = '/home/lab16/jupyter_home/models/ResNet50_1e-05_adam_CosineAnnealing_example.pth' # 0.6774193548387096\n",
    "# model_path = '/home/lab16/jupyter_home/models/EfficientNetb4_0.001_adam_CosineAnnealing_example.pth' # 0.7096774193548387\n",
    "# model_path = '/home/lab16/jupyter_home/models/EfficientNetb4_0.001_Lamb_CosineAnnealing_example.pth' # 0.6774193548387096\n",
    "# model_path = '/home/lab16/jupyter_home/models/EfficientNetb4_1e-05_rmsprop_CosineAnnealing_example.pth' # 0.6129032258064516\n",
    "# model_path = '/home/lab16/jupyter_home/models/EfficientNetb4_1e-05_nadam_CosineAnnealing_example.pth' # 0.5806451612903226\n",
    "\n",
    "#########################################################################################################\n",
    "# model_path = '/home/lab16/jupyter_home/models/jy/EfficientNetb4_0.0001_adam_CosineAnnealing_example.pth' # 0.6774193548387096\n",
    "# model_path = '/home/lab16/jupyter_home/models/jy/EfficientNetb4_0.0001_Lamb_CosineAnnealing_example.pth' # 0.41935483870967744\n",
    "# model_path = '/home/lab16/jupyter_home/models/jy/EfficientNetb4_0.0001_nadam_CosineAnnealing_example.pth' # 0.6774193548387096\n",
    "# model_path = '/home/lab16/jupyter_home/models/jy/EfficientNetb4_0.0001_rmsprop_CosineAnnealing_example.pth' # 0.6451612903225806\n",
    "# model_path = '/home/lab16/jupyter_home/models/jy/EfficientNetb4_0.001_nadam_CosineAnnealing_example.pth' # 0.6451612903225806\n",
    "# model_path = '/home/lab16/jupyter_home/models/jy/EfficientNetb4_0.001_rmsprop_CosineAnnealing_example.pth' # 0.6774193548387096\n",
    "\n",
    "# model_path = '/home/lab16/jupyter_home/models/jy/RegNet_0.0001_adam_CosineAnnealing_example.pth' # 0.8387096774193549\n",
    "# model_path = '/home/lab16/jupyter_home/models/jy/RegNet_0.0001_Lamb_CosineAnnealing_example.pth' # 0.6129032258064516\n",
    "# model_path = '/home/lab16/jupyter_home/models/jy/RegNet_0.0001_nadam_CosineAnnealing_example.pth' # 0.7096774193548387\n",
    "# model_path = '/home/lab16/jupyter_home/models/jy/RegNet_0.0001_rmsprop_CosineAnnealing_example.pth' # 0.6774193548387096\n",
    "\n",
    "# model_path = '/home/lab16/jupyter_home/models/jy/ResNet50_0.0001_adam_CosineAnnealing_example.pth' # 0.41935483870967744\n",
    "# model_path = '/home/lab16/jupyter_home/models/jy/ResNet50_0.0001_Lamb_CosineAnnealing_example.pth' # 0.6451612903225806\n",
    "# model_path = '/home/lab16/jupyter_home/models/jy/ResNet50_0.0001_nadam_CosineAnnealing_example.pth' # 0.6451612903225806\n",
    "# model_path = '/home/lab16/jupyter_home/models/jy/ResNet50_0.0001_rmsprop_CosineAnnealing_example.pth' # 0.6774193548387096\n",
    "# model_path = '/home/lab16/jupyter_home/models/jy/ResNet50_0.001_nadam_CosineAnnealing_example.pth' # 0.2903225806451613\n",
    "# model_path = '/home/lab16/jupyter_home/models/jy/ResNet50_1e-05_nadam_CosineAnnealing_example.pth' # 0.6129032258064516\n",
    "# model_path = '/home/lab16/jupyter_home/models/jy/ResNet50_1e-05_rmsprop_CosineAnnealing_example.pth' # 0.5483870967741935"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9d47ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/lab16/jupyter_home/test_img/test_all/' \n",
    "# path = '/home/lab16/jupyter_home/test_img/test_one/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d4d2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_model = 'resnet'\n",
    "# used_model = 'efficientnet'\n",
    "# used_model = 'regnet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e63c13",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac329bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from os.path import join as opj\n",
    "from glob import glob\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import albumentations as A\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25c600b",
   "metadata": {},
   "source": [
    "# Dataset & Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddad2d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_dataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        total_images_path = glob(path + '*.jpg')\n",
    "        file_names = []\n",
    "        for i in range(len(total_images_path)):\n",
    "            file_names.append(os.path.basename(total_images_path[i]))\n",
    "            file_names.sort()\n",
    "        file_names = np.array(file_names)\n",
    "\n",
    "        self.test_file_name = file_names\n",
    "        self.transform = transform\n",
    "\n",
    "        print(f'Test Dataset size : {len(self.test_file_name)}')\n",
    "        print(self.test_file_name)\n",
    "\n",
    "    def __getitem__(self, idx): # test 경로에 있는 png 이미지 읽어서 float32로 변환\n",
    "        image = cv2.imread(opj(path, self.test_file_name[idx])).astype(np.float32)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0  # BGR=>RGB 변환\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(torch.from_numpy(image.transpose(2,0,1)))\n",
    "\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.test_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fa36578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_augmentation(img_size):\n",
    "    transform = transforms.Compose([\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                transforms.Normalize(mean=(0.744859, 0.735139, 0.711357), std=(0.100712, 0.120692, 0.167998)),  \n",
    "                ])\n",
    "    \n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96dd3ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset size : 31\n",
      "['25222_1.jpg' '25222_2.jpg' '25222_3.jpg' '25222_4.jpg' '25228_1.jpg'\n",
      " '35211_1.jpg' '35211_2.jpg' '35211_3.jpg' '35211_4.jpg' '35584_1.jpg'\n",
      " '35584_2.jpg' '35585_1.jpg' '45030_1.jpg' '45030_2.jpg' '45657_1.jpg'\n",
      " '45657_2.jpg' '45657_3.jpg' '45659_1.jpg' '45659_2.jpg' '45660_1.jpg'\n",
      " '45660_2.jpg' '45661_1.jpg' '45661_2.jpg' '55034_1.jpg' '55701_1.jpg'\n",
      " '55701_2.jpg' '55701_3.jpg' '55701_4.jpg' '55702_1.jpg' '55702_2.jpg'\n",
      " '55702_3.jpg']\n"
     ]
    }
   ],
   "source": [
    "test_transform = get_test_augmentation(img_size=256)\n",
    "test_dataset = Test_dataset(path, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=5, shuffle=False, num_workers=0, collate_fn=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbc8726",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48e9de16",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':256,\n",
    "    'EPOCHS':50,\n",
    "    'PATIENCE':10,\n",
    "    'class':14\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eacb5a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet50, self).__init__()\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        modules = list(model.children())[:-1]\n",
    "        self.feature_extract = nn.Sequential(*modules)\n",
    "        self.fc1 = nn.Linear(2048, 1000)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1000,CFG['class'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extract(x)\n",
    "        # x = x.mean(dim=(-2, -1))\n",
    "        # (batch, 2048, 4, 4)\n",
    "#         x = torch.squeeze(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        out = self.fc2(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1263d7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetb4(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EfficientNetb4, self).__init__()\n",
    "        model = models.efficientnet_b4(pretrained=True)\n",
    "        modules = list(model.children())[:-1]\n",
    "        self.feature_extract = nn.Sequential(*modules)\n",
    "        self.fc1 = nn.Linear(1792, 1000)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1000, CFG['class'])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extract(x)\n",
    "        # (batch, 1792, 1, 1)\n",
    "#         x = torch.squeeze(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        out = self.fc2(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a09b8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegNet, self).__init__()\n",
    "        model = models.regnet_y_16gf(pretrained=True)\n",
    "        modules = list(model.children())[:-1]\n",
    "        self.feature_extract = nn.Sequential(*modules)\n",
    "        self.fc1 = nn.Linear(3024, 1000)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(1000, CFG['class'])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extract(x)\n",
    "        # (batch, 3024, 1, 1)\n",
    "        \n",
    "#         x = torch.squeeze(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = self.relu(self.fc1(x))\n",
    "        out = self.fc2(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f010d3",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91f9195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(encoder_name, test_loader, device, model_path):\n",
    "    if encoder_name == 'resnet':\n",
    "        model = ResNet50().to(device)\n",
    "    elif encoder_name == 'efficientnet':\n",
    "        model = EfficientNetb4().to(device)\n",
    "    elif encoder_name == 'regnet':\n",
    "        model = RegNet().to(device)\n",
    "        \n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    preds_list = []\n",
    "    with torch.no_grad():\n",
    "        for images in tqdm(test_loader):\n",
    "            images = torch.as_tensor(images, device=device, dtype=torch.float32)\n",
    "            preds = model(images)\n",
    "            preds = torch.softmax(preds, dim=1)\n",
    "            preds_list.extend(preds.cpu().tolist())\n",
    "\n",
    "    return np.array(preds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb1b48e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9664caca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 7/7 [00:00<00:00, 12.13it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_arr = predict(used_model, test_loader, device, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab29a3fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.22122395e-01, 3.94745357e-03, 6.58736099e-03, 5.28238481e-04,\n",
       "        2.29808129e-03, 1.04042396e-01, 1.86050609e-02, 1.92900875e-03,\n",
       "        4.03520139e-03, 2.30677449e-03, 7.33678229e-03, 2.04428062e-02,\n",
       "        2.31486117e-03, 3.50349769e-03],\n",
       "       [7.68463075e-01, 2.75711343e-02, 3.94144421e-03, 9.95691982e-04,\n",
       "        4.05096821e-03, 1.46990657e-01, 1.34162670e-02, 4.15385934e-03,\n",
       "        4.60213004e-03, 3.33259604e-03, 7.00599235e-03, 8.21705256e-03,\n",
       "        3.36582004e-03, 3.89343197e-03],\n",
       "       [4.16527212e-01, 1.70977470e-02, 2.88932235e-03, 1.31745159e-03,\n",
       "        1.31160964e-03, 5.19491851e-01, 8.19164515e-03, 3.27214389e-03,\n",
       "        2.47555645e-03, 3.53136845e-03, 6.04927167e-03, 9.57560632e-03,\n",
       "        5.22863213e-03, 3.04055680e-03],\n",
       "       [5.13879716e-01, 2.86807530e-02, 1.02039501e-02, 1.92078296e-03,\n",
       "        3.41979438e-03, 3.08058053e-01, 4.47958708e-03, 5.84823312e-03,\n",
       "        4.68300562e-03, 3.61979380e-03, 6.35223165e-02, 4.11740169e-02,\n",
       "        5.93530713e-03, 4.57464810e-03],\n",
       "       [8.34720075e-01, 7.41814822e-03, 1.85982848e-03, 8.65696056e-04,\n",
       "        4.97522252e-03, 9.00147576e-03, 1.22517357e-02, 5.73964464e-03,\n",
       "        2.63979621e-02, 6.01951517e-02, 6.71047857e-03, 1.72540601e-02,\n",
       "        1.77954684e-03, 1.08309481e-02],\n",
       "       [4.37504143e-01, 2.16452102e-03, 1.95163097e-02, 5.52958867e-04,\n",
       "        2.85249599e-03, 3.26194704e-01, 3.95566178e-03, 1.71506451e-03,\n",
       "        1.30628617e-02, 2.73426785e-03, 5.76945655e-02, 1.24340385e-01,\n",
       "        2.21745041e-03, 5.49459737e-03],\n",
       "       [4.14848894e-01, 1.75797381e-02, 1.61141492e-02, 2.95251305e-03,\n",
       "        3.82725406e-03, 3.58687252e-01, 1.53879998e-02, 1.50125269e-02,\n",
       "        1.51631795e-02, 9.26488452e-03, 2.79815365e-02, 8.76792520e-02,\n",
       "        6.59843534e-03, 8.90238583e-03],\n",
       "       [7.66463339e-01, 5.80788823e-03, 9.93187726e-02, 1.59312517e-03,\n",
       "        4.52264026e-03, 5.74871060e-03, 1.61127578e-02, 3.18097812e-03,\n",
       "        1.85163822e-02, 3.71034932e-03, 2.18650196e-02, 4.11871970e-02,\n",
       "        2.68951547e-03, 9.28325392e-03],\n",
       "       [9.17566866e-02, 9.24014393e-03, 9.46882218e-02, 2.20593438e-03,\n",
       "        9.80204344e-03, 8.96613747e-02, 1.83127314e-01, 1.66263301e-02,\n",
       "        1.98124036e-01, 9.88357365e-02, 2.59145331e-02, 6.24828897e-02,\n",
       "        3.19413692e-02, 8.55934620e-02],\n",
       "       [1.65366661e-02, 4.87917662e-02, 5.85928606e-03, 7.11369932e-01,\n",
       "        1.63586047e-02, 3.64765264e-02, 1.82359968e-03, 3.16973031e-02,\n",
       "        5.12530049e-03, 1.44271934e-02, 6.75279507e-03, 3.61258909e-02,\n",
       "        5.11258394e-02, 1.75292790e-02],\n",
       "       [2.00877637e-02, 2.50497051e-02, 1.00834174e-02, 5.20511806e-01,\n",
       "        1.10405404e-02, 6.82952479e-02, 3.69226956e-03, 2.12624505e-01,\n",
       "        1.61166508e-02, 1.46059161e-02, 3.32981646e-02, 2.13209018e-02,\n",
       "        3.60831730e-02, 7.18994346e-03],\n",
       "       [8.42699930e-02, 2.76741367e-02, 6.67897519e-03, 1.12373913e-02,\n",
       "        4.55459386e-01, 2.37026870e-01, 4.43434343e-02, 1.99257825e-02,\n",
       "        1.74879376e-02, 2.08167322e-02, 2.51136106e-02, 3.28004733e-02,\n",
       "        8.13085865e-03, 9.03443713e-03],\n",
       "       [5.02572511e-04, 2.64098751e-04, 2.01106857e-04, 8.57925697e-05,\n",
       "        8.57323830e-05, 9.96293962e-01, 1.58301467e-04, 1.33673806e-04,\n",
       "        6.00683670e-05, 1.11486865e-04, 1.22223180e-04, 1.59729866e-03,\n",
       "        2.49595061e-04, 1.34046815e-04],\n",
       "       [1.41483254e-03, 1.67775259e-03, 6.65202446e-04, 5.51086850e-04,\n",
       "        6.52794668e-04, 8.94967020e-01, 1.50338266e-04, 2.59712426e-04,\n",
       "        3.41624254e-04, 5.99704566e-04, 7.24912097e-04, 9.67227295e-02,\n",
       "        9.07726819e-04, 3.64529551e-04],\n",
       "       [3.95268537e-02, 3.65562504e-03, 1.00377318e-03, 6.66489243e-04,\n",
       "        2.94701825e-03, 3.11018340e-03, 7.60804594e-01, 6.51731789e-02,\n",
       "        1.19998297e-02, 8.81834626e-02, 4.37065819e-03, 1.17443048e-03,\n",
       "        3.04326043e-03, 1.43406624e-02],\n",
       "       [1.65777858e-02, 4.78544598e-03, 7.64586264e-04, 1.60877150e-03,\n",
       "        2.30791839e-03, 1.03182588e-02, 3.86430651e-01, 3.68104458e-01,\n",
       "        8.42040684e-03, 1.69497564e-01, 3.68429581e-03, 1.65743032e-03,\n",
       "        8.11816100e-03, 1.77242514e-02],\n",
       "       [6.41534328e-02, 5.30508347e-03, 1.20104188e-02, 1.22718618e-03,\n",
       "        5.45300636e-03, 1.50208458e-01, 5.63798487e-01, 2.88766660e-02,\n",
       "        1.12732835e-02, 4.61319350e-02, 9.79281310e-03, 1.37598338e-02,\n",
       "        3.75236687e-03, 8.42571110e-02],\n",
       "       [9.82018039e-02, 7.35149998e-03, 5.61306486e-03, 8.68361734e-04,\n",
       "        2.51764595e-03, 7.98908435e-03, 9.92240608e-02, 4.04341556e-02,\n",
       "        6.56426966e-01, 1.76056866e-02, 1.54744620e-02, 1.45349810e-02,\n",
       "        7.70605030e-03, 2.60521639e-02],\n",
       "       [4.35317717e-02, 6.96567260e-03, 8.46061762e-03, 5.45086106e-03,\n",
       "        3.57352779e-03, 9.75648910e-02, 1.39947712e-01, 5.49872339e-01,\n",
       "        4.41541933e-02, 1.58516429e-02, 4.10607345e-02, 9.53633059e-03,\n",
       "        1.85673423e-02, 1.54623864e-02],\n",
       "       [2.92740874e-02, 5.74767264e-03, 4.67275362e-03, 7.66541634e-04,\n",
       "        2.06901017e-03, 4.68927296e-03, 2.14346368e-02, 7.13429088e-03,\n",
       "        1.89226821e-01, 5.48459589e-01, 5.20096812e-03, 5.37668588e-03,\n",
       "        1.45936981e-02, 1.61353886e-01],\n",
       "       [5.96522121e-03, 3.76334996e-03, 4.57977789e-04, 1.82026147e-03,\n",
       "        3.32091673e-04, 3.32762748e-02, 1.10808127e-02, 8.71191621e-01,\n",
       "        2.56769126e-03, 5.95681854e-02, 2.55909469e-03, 2.45700148e-03,\n",
       "        3.87868285e-03, 1.08175259e-03],\n",
       "       [1.37946717e-02, 7.01114303e-03, 8.90202168e-03, 1.43008698e-02,\n",
       "        4.30167746e-03, 2.20683396e-01, 7.60795502e-03, 6.47391826e-02,\n",
       "        1.38904238e-02, 1.11642331e-01, 4.80530709e-01, 2.39670668e-02,\n",
       "        1.98063683e-02, 8.82221851e-03],\n",
       "       [5.23203565e-03, 7.30691361e-04, 2.87825102e-03, 3.06247239e-04,\n",
       "        8.68175994e-04, 9.47591305e-01, 4.15534712e-03, 3.22213885e-03,\n",
       "        6.21267420e-04, 1.50652882e-03, 2.84014791e-02, 1.71791518e-03,\n",
       "        1.12520216e-03, 1.64353126e-03],\n",
       "       [3.62623157e-03, 4.59709996e-03, 1.01883546e-03, 1.16766058e-03,\n",
       "        8.34746927e-04, 8.63406777e-01, 3.36031371e-04, 6.82049838e-04,\n",
       "        6.92673668e-04, 1.25184515e-03, 1.15460902e-03, 1.19980089e-01,\n",
       "        7.68999744e-04, 4.82350035e-04],\n",
       "       [1.07070198e-03, 1.69756485e-03, 7.17317045e-04, 8.67061084e-04,\n",
       "        6.69593748e-04, 5.64888213e-03, 3.62930633e-03, 6.66969195e-02,\n",
       "        2.62346175e-02, 8.43046175e-04, 6.10092073e-04, 1.09320018e-03,\n",
       "        8.88163567e-01, 2.05812044e-03],\n",
       "       [1.40607506e-02, 1.66486353e-02, 1.54066680e-03, 1.08484766e-02,\n",
       "        1.86511909e-03, 1.00772157e-02, 3.26168388e-02, 6.46008909e-01,\n",
       "        1.94190964e-02, 1.56694259e-02, 4.11649421e-03, 3.15557118e-03,\n",
       "        1.93104520e-01, 3.08682378e-02],\n",
       "       [9.56045580e-04, 3.49889765e-03, 2.58107320e-04, 3.84490052e-03,\n",
       "        3.47167370e-04, 1.03570824e-03, 4.58438852e-04, 3.34713124e-02,\n",
       "        4.00111359e-03, 7.78625777e-04, 3.06150439e-04, 8.41378351e-04,\n",
       "        9.48269665e-01, 1.93252717e-03],\n",
       "       [6.46789267e-04, 9.48125089e-04, 1.24420694e-04, 3.15116416e-03,\n",
       "        1.69500257e-04, 2.35337904e-03, 6.89980667e-03, 9.58070338e-01,\n",
       "        1.93801930e-03, 1.22569257e-03, 4.56994108e-04, 3.46763438e-04,\n",
       "        2.31451448e-02, 5.23925584e-04],\n",
       "       [2.46717110e-02, 1.48722832e-03, 6.90686889e-03, 2.41443238e-04,\n",
       "        1.79524743e-03, 5.06158452e-03, 4.56262112e-01, 2.37452937e-03,\n",
       "        2.33419379e-03, 1.13306404e-03, 5.98092040e-04, 8.93758144e-04,\n",
       "        8.17567483e-03, 4.88064528e-01],\n",
       "       [3.86808580e-03, 5.82988898e-04, 1.83590956e-03, 1.00364385e-04,\n",
       "        6.41024555e-04, 9.47442080e-04, 8.54723990e-01, 2.61821109e-03,\n",
       "        1.01078558e-03, 1.49232778e-03, 2.12776373e-04, 2.82888708e-04,\n",
       "        3.00898962e-03, 1.28674239e-01],\n",
       "       [8.48050136e-03, 1.28819968e-03, 1.95151079e-03, 2.18287591e-04,\n",
       "        1.12208421e-03, 7.05647341e-04, 9.41230774e-01, 6.01415802e-03,\n",
       "        2.13877996e-03, 1.71821320e-03, 5.96430851e-04, 4.51793283e-04,\n",
       "        1.14289317e-02, 2.26547420e-02]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e9a9f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  5,  0,  0,  0,  0,  0,  8,  3,  3,  4,  5,  5,  6,  6,  6,\n",
       "        8,  7,  9,  7, 10,  5,  5, 12,  7, 12,  7, 13,  6,  6])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_arr.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "175b62a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['25222_대만)망고케익184g', '25228_대만)파인애플케익184G', '35211_매일유업)데르뜨130G', '35584_매일데르뜨파인애플90G', '35585_매일데르뜨감귤90G', '45030_돌황도666G', '45657_씨제이)쁘티첼(요거젤리복숭아)', '45658_씨제이)쁘티첼(요거젤리밀감)', '45659_씨제이)쁘티첼(요거젤리딸기)', '45660_씨제이)쁘티첼(요거젤리화이트코코)', '45661_씨제이)쁘티첼(요거젤리블루베리)', '55034_돌트로피칼666G', '55701_쁘띠첼요거젤리밀감', '55702_쁘띠첼요거젤리복숭아']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "754ee639",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {string : i for i, string in enumerate(labels)}\n",
    "label_decoder = {val:key for key, val in labels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67cb31a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25222_대만)망고케익184g\n",
      "25222_대만)망고케익184g\n",
      "45030_돌황도666G\n",
      "25222_대만)망고케익184g\n",
      "25222_대만)망고케익184g\n",
      "25222_대만)망고케익184g\n",
      "25222_대만)망고케익184g\n",
      "25222_대만)망고케익184g\n",
      "45659_씨제이)쁘티첼(요거젤리딸기)\n",
      "35584_매일데르뜨파인애플90G\n",
      "35584_매일데르뜨파인애플90G\n",
      "35585_매일데르뜨감귤90G\n",
      "45030_돌황도666G\n",
      "45030_돌황도666G\n",
      "45657_씨제이)쁘티첼(요거젤리복숭아)\n",
      "45657_씨제이)쁘티첼(요거젤리복숭아)\n",
      "45657_씨제이)쁘티첼(요거젤리복숭아)\n",
      "45659_씨제이)쁘티첼(요거젤리딸기)\n",
      "45658_씨제이)쁘티첼(요거젤리밀감)\n",
      "45660_씨제이)쁘티첼(요거젤리화이트코코)\n",
      "45658_씨제이)쁘티첼(요거젤리밀감)\n",
      "45661_씨제이)쁘티첼(요거젤리블루베리)\n",
      "45030_돌황도666G\n",
      "45030_돌황도666G\n",
      "55701_쁘띠첼요거젤리밀감\n",
      "45658_씨제이)쁘티첼(요거젤리밀감)\n",
      "55701_쁘띠첼요거젤리밀감\n",
      "45658_씨제이)쁘티첼(요거젤리밀감)\n",
      "55702_쁘띠첼요거젤리복숭아\n",
      "45657_씨제이)쁘티첼(요거젤리복숭아)\n",
      "45657_씨제이)쁘티첼(요거젤리복숭아)\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "\n",
    "for i in range(len(test_dataset.test_file_name)):\n",
    "    prediction = label_decoder[predict_arr.argmax(axis=1)[i]]\n",
    "    print(prediction)\n",
    "    pred_list.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44e323b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4471c185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "439a5567",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39c1ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cbf963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_images_path = glob(path + '*.jpg')\n",
    "file_names = []\n",
    "for i in range(len(total_images_path)):\n",
    "    file_names.append(os.path.basename(total_images_path[i])[:5])\n",
    "    file_names.sort()\n",
    "# file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bd7e706",
   "metadata": {},
   "outputs": [],
   "source": [
    "_pred_list = []\n",
    "for i in range(len(total_images_path)):\n",
    "    _pred_list.append(pred_list[i][:5])\n",
    "# _pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c381ef6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5483870967741935"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(_pred_list, file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16868207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "535c5d41",
   "metadata": {},
   "source": [
    "with validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3ced8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "# import torch.nn.functional as F\n",
    "# import albumentations as A\n",
    "# import albumentations.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d060fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_valid_data(data_dir):\n",
    "#     img_valid_list = []\n",
    "#     label_valid_list = []\n",
    "    \n",
    "#     image_path = os.path.join(data_dir, 'dessert')\n",
    "    \n",
    "#     for product_name in os.listdir(image_path):\n",
    "#         product_path = os.path.join(image_path, product_name)\n",
    "#         if os.path.isdir(product_path):\n",
    "#             # get image path\n",
    "#             img_valid_list.extend(glob(os.path.join(product_path, '*.jpg')))\n",
    "#             img_valid_list.extend(glob(os.path.join(product_path, '*.png')))\n",
    "#             label = list(product_name[:5])\n",
    "            \n",
    "#             # get label\n",
    "#             label_valid_list.append(''.join(label))\n",
    "                \n",
    "#     return img_valid_list, label_valid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45d3d3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def valid_data_blanced(img, label):\n",
    "#     x = []\n",
    "#     y = []\n",
    "    \n",
    "#     for i in range(CFG['class']):\n",
    "#         _img = img[(i * 15): ((i + 1) * 15)]\n",
    "#         _label = label[i]\n",
    "        \n",
    "#         for img_product in _img:\n",
    "#             x.append(img_product)\n",
    "#             y.append(_label)\n",
    "            \n",
    "#     return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "973a8cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_valid_list, label_valid_list = get_valid_data('./Data/product_image/Validation/')\n",
    "# x_valid, y_valid = valid_data_blanced(img_valid_list, label_valid_list)\n",
    "# len(label_valid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b00b0fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# le2 = preprocessing.LabelEncoder()\n",
    "# targets_y = le2.fit_transform(y_valid)\n",
    "# targets_y = torch.as_tensor(targets_y)\n",
    "# one_hot_valid_y = F.one_hot(targets_y)\n",
    "# one_hot_valid_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e85ca4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AlbumentationsCustomDataset(Dataset):\n",
    "#     def __init__(self, img_path_list, label_list, train_mode=True, transforms=None):\n",
    "#         self.transforms = transforms\n",
    "#         self.train_mode = train_mode\n",
    "#         self.img_path_list = img_path_list\n",
    "#         self.label_list = label_list\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         img_path = self.img_path_list[index]\n",
    "#         # Get image data\n",
    "#         image = cv2.imread(img_path)\n",
    "        \n",
    "#         # By default OpenCV uses BGR color space for color images,\n",
    "#         # so we need to convert the image to RGB color space.\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#         if self.train_mode:\n",
    "# #             image = image.astype(np.int16)\n",
    "#             augmented = self.transforms(image=image)\n",
    "#             image = augmented['image']\n",
    "#             label = self.label_list[index]\n",
    "#             return image, label\n",
    "#         else:\n",
    "#             image = self.transforms(image)\n",
    "#             label = self.label_list[index]\n",
    "#             return image, label\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.img_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8305a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A_test_transform = albumentations.Compose([\n",
    "#                                     A.Resize(256, 256),\n",
    "#                                     A.Normalize(mean=(0.744859, 0.735139, 0.711357), std=(0.100712, 0.120692, 0.167998)),  \n",
    "# #                                     A.pytorch.transforms.ToTensor(),\n",
    "#                                     A.pytorch.transforms.ToTensorV2(transpose_mask=True),\n",
    "#                                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ccfea251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A_vali_dataset = AlbumentationsCustomDataset(x_valid, one_hot_valid_y, train_mode=True, transforms=A_test_transform)\n",
    "# A_vali_loader = DataLoader(A_vali_dataset, batch_size = 5, shuffle=False, num_workers=0, collate_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85729923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_for_acc(model, test_loader, device):\n",
    "#     model.eval()\n",
    "#     model_pred = []\n",
    "#     with torch.no_grad():\n",
    "#         for img, label in tqdm(iter(test_loader)):\n",
    "#             img = img.float().to(device)\n",
    "            \n",
    "#             pred_logit = model(img)\n",
    "#             pred_logit = pred_logit.squeeze().detach().cpu()\n",
    "            \n",
    "#             model_pred.extend(pred_logit.tolist())\n",
    "#     return model_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76b9b1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7336bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if used_model == 'resnet':\n",
    "#     model = ResNet50().to(device)\n",
    "# elif used_model == 'efficientnet':\n",
    "#     model = EfficientNetb4().to(device)\n",
    "# elif used_model == 'regnet':\n",
    "#     model = RegNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8932b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(checkpoint)\n",
    "\n",
    "# preds = predict_for_acc(model, A_vali_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6fdb7cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_labels = np.argmax(preds, axis=1)\n",
    "# true_labels = one_hot_valid_y.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f0b6e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# accuracy_score(true_labels, pred_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_16] *",
   "language": "python",
   "name": "conda-env-pytorch_16-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
