{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d39f139f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun  8 13:45:09 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.142.00   Driver Version: 450.142.00   CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   46C    P0    34W /  70W |      0MiB / 15109MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25decd3f",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "760e0a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aacd6ae",
   "metadata": {},
   "source": [
    "## Image Pre-Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb9f3c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_png = sorted(glob('/home/lab17/jupyter_home/Data/bdata_snacks/*.jpg'))\n",
    "test_png = sorted(glob('/home/lab17/jupyter_home/git/git_jy/test_dataset/*.jpg'))\n",
    "\n",
    "# files = os.listdir('/home/lab17/jupyter_home/Data/bdata_snacks')\n",
    "# files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38d2df20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311 311\n",
      "7 7\n"
     ]
    }
   ],
   "source": [
    "print(len(train_png), len(set(train_png)))\n",
    "print(len(test_png), len(set(test_png)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a41bbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "files = os.listdir('/home/lab17/jupyter_home/Data/bdata_snacks')\n",
    "train_labels = sorted(files)\n",
    "train_dict = {i:l[:-4] for i, l in zip(range(311), train_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8f6e004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path)[:,:,::-1]\n",
    "    img = cv2.resize(img, (384, 384),interpolation = cv2.INTER_AREA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3dd8e7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 7/7 [00:00<00:00, 131.86it/s]\n"
     ]
    }
   ],
   "source": [
    "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
    "test_imgs = [img_load(n) for n in tqdm(test_png)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d65f751",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/lab17/jupyter_home/Data/bdata_snacks_384.npy', np.array(train_imgs))\n",
    "np.save('/home/lab17/jupyter_home/Data/test_snacks_384.npy', np.array(test_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb6789c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = np.load('/home/lab17/jupyter_home/Data/bdata_snacks_384.npy')\n",
    "test_imgs = np.load('/home/lab17/jupyter_home/Data/test_snacks_384.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c34b549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 평균 0.7097844470485838 0.633531969760679 0.5547763538712672\n",
      "train 표준편차 0.2033680463341466 0.21580010480417353 0.24844798400637713\n"
     ]
    }
   ],
   "source": [
    "# meanRGB = [np.mean(x, axis=(0,1)) for x in train_imgs]\n",
    "# stdRGB = [np.std(x, axis=(0,1)) for x in train_imgs]\n",
    "\n",
    "# meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "# meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "# meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "# stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "# stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "# stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "# print(\"train 평균\",meanR, meanG, meanB)\n",
    "# print(\"train 표준편차\",stdR, stdG, stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69babf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 평균 0.5675011557357318 0.5264908952947499 0.42253120486475837\n",
      "test 표준편차 0.2274250397086117 0.23777227831017764 0.25968101419272444\n"
     ]
    }
   ],
   "source": [
    "# meanRGB = [np.mean(x, axis=(0,1)) for x in test_imgs]\n",
    "# stdRGB = [np.std(x, axis=(0,1)) for x in test_imgs]\n",
    "\n",
    "# meanR = np.mean([m[0] for m in meanRGB])/255\n",
    "# meanG = np.mean([m[1] for m in meanRGB])/255\n",
    "# meanB = np.mean([m[2] for m in meanRGB])/255\n",
    "\n",
    "# stdR = np.mean([s[0] for s in stdRGB])/255\n",
    "# stdG = np.mean([s[1] for s in stdRGB])/255\n",
    "# stdB = np.mean([s[2] for s in stdRGB])/255\n",
    "\n",
    "# print(\"test 평균\",meanR, meanG, meanB)\n",
    "# print(\"test 표준편차\",stdR, stdG, stdB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7221433",
   "metadata": {},
   "source": [
    "## Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c99b6f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, mode='train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.mode=mode\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_paths[idx]\n",
    "        if self.mode == 'train':\n",
    "            train_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.709784, 0.633531, 0.554776],\n",
    "                                    std = [0.203368, 0.215800, 0.248448]),\n",
    "                transforms.RandomCrop(224),\n",
    "                transforms.RandomPerspective(),\n",
    "                transforms.RandomAffine((-45, 45)),  # x, y축으로 이미지 늘림\n",
    "                transforms.RandomRotation((0,80)),\n",
    "                transforms.ColorJitter(brightness=0.5),\n",
    "            ])\n",
    "\n",
    "\n",
    "#             train_transform = transforms.Compose([\n",
    "#                 transforms.ToTensor(),\n",
    "#                 transforms.Normalize(mean = [0.709784, 0.633531, 0.554776],\n",
    "#                                     std = [0.203368, 0.215800, 0.248448]),\n",
    "#                 transforms.RandomAffine((-45, 45)),\n",
    "#                 transforms.RandomRotation((0,80))       #  이미지를 랜덤으로 degrees 각도로 회전한다.\n",
    "#             ])\n",
    "\n",
    "            img = train_transform(img)\n",
    "        if self.mode == 'test':\n",
    "            test_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean = [0.567501, 0.526491, 0.422531],\n",
    "                                     std = [0.227425, 0.237772, 0.259681]),\n",
    "\n",
    "            ])\n",
    "            img = test_transform(img)\n",
    "\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self,mode = 'train'):\n",
    "        super(Network, self).__init__()\n",
    "        self.mode = mode\n",
    "        if self.mode == 'train':\n",
    "          self.model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=311, drop_path_rate = 0.2)\n",
    "        if self.mode == 'test':\n",
    "          self.model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=311, drop_path_rate = 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77e16652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "#     score = f1_score(real, pred, average=\"macro\")\n",
    "    score = accuracy_score(real, pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa4b3a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(seed = 2022):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "main(2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcc95a6",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76937545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/70    time : 9s/624s\n",
      "TRAIN    loss : 5.78945    acc : 0.00322\n",
      "epoch : 2/70    time : 5s/337s\n",
      "TRAIN    loss : 5.71250    acc : 0.00322\n",
      "epoch : 3/70    time : 5s/332s\n",
      "TRAIN    loss : 5.61914    acc : 0.02251\n",
      "epoch : 4/70    time : 5s/326s\n",
      "TRAIN    loss : 5.49805    acc : 0.05466\n",
      "epoch : 5/70    time : 5s/322s\n",
      "TRAIN    loss : 5.39023    acc : 0.08360\n",
      "epoch : 6/70    time : 5s/317s\n",
      "TRAIN    loss : 5.15430    acc : 0.03859\n",
      "epoch : 7/70    time : 5s/314s\n",
      "TRAIN    loss : 4.94238    acc : 0.06109\n",
      "epoch : 8/70    time : 5s/313s\n",
      "TRAIN    loss : 4.55391    acc : 0.17363\n",
      "epoch : 9/70    time : 5s/303s\n",
      "TRAIN    loss : 4.20850    acc : 0.18006\n",
      "epoch : 10/70    time : 5s/296s\n",
      "TRAIN    loss : 3.55503    acc : 0.20900\n",
      "epoch : 11/70    time : 5s/295s\n",
      "TRAIN    loss : 2.68528    acc : 0.35691\n",
      "epoch : 12/70    time : 5s/290s\n",
      "TRAIN    loss : 1.90090    acc : 0.51768\n",
      "epoch : 13/70    time : 5s/284s\n",
      "TRAIN    loss : 1.14751    acc : 0.74277\n",
      "epoch : 14/70    time : 5s/279s\n",
      "TRAIN    loss : 0.73156    acc : 0.81350\n",
      "epoch : 15/70    time : 5s/274s\n",
      "TRAIN    loss : 0.48989    acc : 0.86174\n",
      "epoch : 16/70    time : 5s/269s\n",
      "TRAIN    loss : 0.40083    acc : 0.88424\n",
      "epoch : 17/70    time : 5s/262s\n",
      "TRAIN    loss : 0.28955    acc : 0.91640\n",
      "epoch : 18/70    time : 5s/259s\n",
      "TRAIN    loss : 0.28373    acc : 0.92605\n",
      "epoch : 19/70    time : 5s/257s\n",
      "TRAIN    loss : 0.22372    acc : 0.94212\n",
      "epoch : 20/70    time : 5s/251s\n",
      "TRAIN    loss : 0.17278    acc : 0.94212\n",
      "epoch : 21/70    time : 5s/243s\n",
      "TRAIN    loss : 0.19024    acc : 0.93569\n",
      "epoch : 22/70    time : 5s/249s\n",
      "TRAIN    loss : 0.17306    acc : 0.94855\n",
      "epoch : 23/70    time : 5s/231s\n",
      "TRAIN    loss : 0.13024    acc : 0.97106\n",
      "epoch : 24/70    time : 5s/225s\n",
      "TRAIN    loss : 0.11167    acc : 0.96785\n",
      "epoch : 25/70    time : 5s/224s\n",
      "TRAIN    loss : 0.10364    acc : 0.97106\n",
      "epoch : 26/70    time : 5s/217s\n",
      "TRAIN    loss : 0.10958    acc : 0.97428\n",
      "epoch : 27/70    time : 5s/213s\n",
      "TRAIN    loss : 0.08640    acc : 0.98714\n",
      "epoch : 28/70    time : 5s/208s\n",
      "TRAIN    loss : 0.06240    acc : 0.98714\n",
      "epoch : 29/70    time : 5s/202s\n",
      "TRAIN    loss : 0.04554    acc : 0.98714\n",
      "epoch : 30/70    time : 5s/199s\n",
      "TRAIN    loss : 0.10659    acc : 0.97106\n",
      "epoch : 31/70    time : 5s/194s\n",
      "TRAIN    loss : 0.09747    acc : 0.97428\n",
      "epoch : 32/70    time : 5s/187s\n",
      "TRAIN    loss : 0.08347    acc : 0.97428\n",
      "epoch : 33/70    time : 5s/182s\n",
      "TRAIN    loss : 0.05781    acc : 0.98714\n",
      "epoch : 34/70    time : 5s/177s\n",
      "TRAIN    loss : 0.08461    acc : 0.97749\n",
      "epoch : 35/70    time : 5s/174s\n",
      "TRAIN    loss : 0.07187    acc : 0.97428\n",
      "epoch : 36/70    time : 5s/169s\n",
      "TRAIN    loss : 0.05779    acc : 0.98392\n",
      "epoch : 37/70    time : 5s/164s\n",
      "TRAIN    loss : 0.03682    acc : 0.98392\n",
      "epoch : 38/70    time : 5s/158s\n",
      "TRAIN    loss : 0.02437    acc : 0.99357\n",
      "epoch : 39/70    time : 5s/155s\n",
      "TRAIN    loss : 0.06690    acc : 0.97749\n",
      "epoch : 40/70    time : 5s/149s\n",
      "TRAIN    loss : 0.04952    acc : 0.98392\n",
      "epoch : 41/70    time : 5s/143s\n",
      "TRAIN    loss : 0.06080    acc : 0.97749\n",
      "epoch : 42/70    time : 5s/138s\n",
      "TRAIN    loss : 0.03130    acc : 0.99035\n",
      "epoch : 43/70    time : 5s/133s\n",
      "TRAIN    loss : 0.02070    acc : 0.99035\n",
      "epoch : 44/70    time : 5s/129s\n",
      "TRAIN    loss : 0.02001    acc : 0.99357\n",
      "epoch : 45/70    time : 5s/126s\n",
      "TRAIN    loss : 0.02242    acc : 0.99678\n",
      "epoch : 46/70    time : 5s/119s\n",
      "TRAIN    loss : 0.02949    acc : 0.99357\n",
      "epoch : 47/70    time : 5s/114s\n",
      "TRAIN    loss : 0.02405    acc : 0.99035\n",
      "epoch : 48/70    time : 5s/112s\n",
      "TRAIN    loss : 0.01960    acc : 0.99357\n",
      "epoch : 49/70    time : 5s/104s\n",
      "TRAIN    loss : 0.02486    acc : 0.99357\n",
      "epoch : 50/70    time : 5s/99s\n",
      "TRAIN    loss : 0.02668    acc : 0.98714\n",
      "epoch : 51/70    time : 5s/94s\n",
      "TRAIN    loss : 0.00351    acc : 1.00000\n",
      "epoch : 52/70    time : 5s/89s\n",
      "TRAIN    loss : 0.00455    acc : 1.00000\n",
      "epoch : 53/70    time : 5s/84s\n",
      "TRAIN    loss : 0.01101    acc : 0.99678\n",
      "epoch : 54/70    time : 5s/79s\n",
      "TRAIN    loss : 0.01498    acc : 0.99678\n",
      "epoch : 55/70    time : 5s/74s\n",
      "TRAIN    loss : 0.01859    acc : 0.99678\n",
      "epoch : 56/70    time : 5s/69s\n",
      "TRAIN    loss : 0.01299    acc : 0.99678\n",
      "epoch : 57/70    time : 5s/64s\n",
      "TRAIN    loss : 0.02096    acc : 0.99035\n",
      "epoch : 58/70    time : 5s/60s\n",
      "TRAIN    loss : 0.01186    acc : 0.99678\n",
      "epoch : 59/70    time : 5s/54s\n",
      "TRAIN    loss : 0.01045    acc : 0.99678\n",
      "epoch : 60/70    time : 5s/49s\n",
      "TRAIN    loss : 0.01502    acc : 0.99678\n",
      "epoch : 61/70    time : 5s/45s\n",
      "TRAIN    loss : 0.00681    acc : 1.00000\n",
      "epoch : 62/70    time : 5s/40s\n",
      "TRAIN    loss : 0.00597    acc : 1.00000\n",
      "epoch : 63/70    time : 5s/35s\n",
      "TRAIN    loss : 0.00860    acc : 0.99678\n",
      "epoch : 64/70    time : 5s/30s\n",
      "TRAIN    loss : 0.01660    acc : 0.99357\n",
      "epoch : 65/70    time : 5s/25s\n",
      "TRAIN    loss : 0.02576    acc : 0.99357\n",
      "epoch : 66/70    time : 5s/20s\n",
      "TRAIN    loss : 0.01099    acc : 0.99357\n",
      "epoch : 67/70    time : 5s/15s\n",
      "TRAIN    loss : 0.02461    acc : 0.99678\n",
      "epoch : 68/70    time : 5s/10s\n",
      "TRAIN    loss : 0.00541    acc : 0.99678\n",
      "epoch : 69/70    time : 6s/6s\n",
      "TRAIN    loss : 0.01544    acc : 0.99035\n",
      "epoch : 70/70    time : 6s/0s\n",
      "TRAIN    loss : 0.01923    acc : 0.99678\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "batch_size = 34\n",
    "epochs = 70\n",
    "pred_ensemble = []\n",
    "\n",
    "# Train\n",
    "train_dataset = Custom_dataset(np.array(train_imgs), np.array(list(train_dict.keys())), mode='train')\n",
    "train_loader = DataLoader(train_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "# # Val\n",
    "# val_dataset = Custom_dataset(np.array(val_imgs), np.array(val_labels), np.array([]), mode='test')\n",
    "# val_loader = DataLoader(val_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "best=0\n",
    "\n",
    "model = Network().to(device)\n",
    "\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay = 2e-2)\n",
    "optimizer = torch.optim.Adadelta(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler()  \n",
    "\n",
    "best_f1 = 0\n",
    "early_stopping = 0\n",
    "for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "        \n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "    state_dict= model.state_dict()\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    acc : {train_f1:.5f}')\n",
    "#     print(f'Val    loss : {val_loss:.5f}    f1 : {val_f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d21db8",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6e79335",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'epoch':epoch,\n",
    "            'state_dict':state_dict,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scaler': scaler.state_dict(),\n",
    "     }, '/home/lab17/jupyter_home/Model/snacks_311_3.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626037b3",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d335ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ensemble = []\n",
    "batch_size = 34\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "model_test = Network(mode = 'test').to(device)\n",
    "model_test.load_state_dict(torch.load('/home/lab17/jupyter_home/Model/snacks_311_3.pth')['state_dict'])\n",
    "model_test.eval()\n",
    "f_pred = []\n",
    "pred_prob = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in (test_loader):\n",
    "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model_test(x)\n",
    "            pred_prob.extend(pred.detach().cpu().numpy())\n",
    "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30909897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_decoder = {val:key for key, val in label_unique.items()}\n",
    "\n",
    "f_result = [train_dict[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "815a8fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['유기농 쌀떡뻥 25g',\n",
       " '노브랜드 자색고구마칩 110g',\n",
       " '오리온 오징어땅콩 3번들 294g',\n",
       " '유기농 쌀떡뻥 25g',\n",
       " '코코몽 유기농 달고나 25g',\n",
       " '(G) 노브랜드쿠키앤크림샌드720g',\n",
       " '(G) 노브랜드쿠키앤크림샌드720g']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16b3822",
   "metadata": {},
   "source": [
    "##### 정답\n",
    "- 감자깡\n",
    "- 알새우칩\n",
    "- 포스틱\n",
    "- 사또밥\n",
    "- 고래밥\n",
    "- 빠삭칩\n",
    "- 칸츄리콘\n",
    "\n",
    "##### 1번째 : snacks_311\n",
    "\n",
    "- '[농심] 새우깡90g'\n",
    "- '[농심] 알새우칩 68g',\n",
    "- '[농심] 포스틱 84g',\n",
    "- '오리온 치즈뿌린 치킨팝 81g',\n",
    "- '맘스케어 유기농까까 오리지날 43g',\n",
    "- '노브랜드 달콤한꿀깨맛꽈배기 200 g',\n",
    "- '노브랜드 땅콩카라멜콘 230 g'\n",
    "\n",
    "##### 2번째 : snacks_311_2 (실패)\n",
    "\n",
    "- ['단백질 오란다 100g',\n",
    "- '유기농 쌀떡뻥 25g',\n",
    "- '(G) 노브랜드쿠키앤크림샌드720g',\n",
    "- '(G) 노브랜드쿠키앤크림샌드720g',\n",
    "- '(G) 노브랜드쿠키앤크림샌드720g',\n",
    "- '(G) 노브랜드쿠키앤크림샌드720g',\n",
    "- '(G) 노브랜드쿠키앤크림샌드720g']\n",
    "\n",
    "##### 3번째 : snacks_311_3\n",
    "\n",
    "- ['유기농 쌀떡뻥 25g',\n",
    "- '노브랜드 자색고구마칩 110g',\n",
    "- '오리온 오징어땅콩 3번들 294g',\n",
    "- '유기농 쌀떡뻥 25g',\n",
    "- '코코몽 유기농 달고나 25g',\n",
    "- '(G) 노브랜드쿠키앤크림샌드720g',\n",
    "- '(G) 노브랜드쿠키앤크림샌드720g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29110f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_17] *",
   "language": "python",
   "name": "conda-env-pytorch_17-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
